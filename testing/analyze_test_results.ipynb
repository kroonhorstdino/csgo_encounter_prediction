{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   }
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Loading JSON file config/dataset_config.json\nLoading JSON file config/features_info.json\nLoading JSON file config/item_definition_index_map.json\nLoading JSON file config/features_info.json\nLoading JSON file config/features_info.json\n"
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from pathlib import Path\n",
    "from pydoc import locate\n",
    "from typing import List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import (average_precision_score, precision_recall_curve,\n",
    "                             roc_auc_score, roc_curve)\n",
    "from termcolor import colored\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "\n",
    "sys.path.insert(0, str(Path.cwd() / 'preparation/'))\n",
    "sys.path.insert(0, str(Path.cwd() / 'training/'))\n",
    "\n",
    "import data_loader\n",
    "import models\n",
    "import preprocess\n",
    "import prepare_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config\n",
    "#DATASET_CONFIG = data_loader.load_config('config/dataset_config.json')\n",
    "#TRAIN_CONFIG = data_loader.load_config('config/train_config.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sample\n",
    "#sample = data_loader.load_h5_as_df('../../csgo_dataset/processed_files/renegades-vs-g2-m1-inferno.h5', False)\n",
    "sample = data_loader.load_h5_as_df('/home/hueter/csgo_dataset/processed_files/24bhb-vs-shift-m2-nuke.h5', False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tick = 14458.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "load() got an unexpected keyword argument 'pickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-581674de6c76>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred_and_lab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmatch_indecies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'results/first_exp_0/24bhb-vs-shift-m2-nuke_match_indecies.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'results/first_exp_0/24bhb-vs-shift-m2-nuke_die_not_die_acc.npy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpickle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: load() got an unexpected keyword argument 'pickle'"
     ]
    }
   ],
   "source": [
    "pred_and_lab = np.load('results/first_exp_0/24bhb-vs-shift-m2-nuke_predictions_and_labels.npy')\n",
    "labels = pred_and_lab[1]\n",
    "pred = pred_and_lab[0].astype(np.float32)\n",
    "match_indecies = np.load('results/first_exp_0/24bhb-vs-shift-m2-nuke_match_indecies.npy')\n",
    "acc = np.load('results/first_exp_0/24bhb-vs-shift-m2-nuke_die_not_die_acc.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "iloc_index = np.where(match_indecies == tick)[0]\n",
    "print(iloc_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(acc[0],acc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(labels[iloc_index])\n",
    "print(pred[iloc_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}